{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3153a786-8d12-4e93-a18a-9d108fac8722",
   "metadata": {},
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import torch"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9630fd7-ab08-43a0-a2f5-779b66ba8596",
   "metadata": {
    "tags": []
   },
   "source": [
    "from unetr.utilsUnetr.transforms import CropBedd, RandCropByPosNegLabeld, ResizeOrDoNothingd\n",
    "from functools import partial\n",
    "from monai.inferers import sliding_window_inference\n",
    "from unetr.networks.unetr import UNETR\n",
    "import os\n",
    "from unetr.model_module import SegmentationTask\n",
    "from monai.transforms import LoadImage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "import cv2\n",
    "import monai.transforms as transforms\n",
    "import scipy\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from monai import transforms\n",
    "from monai.transforms import LoadImage\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from pydicom import dcmread\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import rt_utils\n",
    "import pydicom\n",
    "from os import listdir\n",
    "import tqdm\n",
    "import json \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4746dea5-1cb8-4cbe-91ee-4e8b2be86cf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "def diceSpecSens(maskGT, maskPred):\n",
    "    predZone=np.where(maskPred==1.0, maskPred,10000)\n",
    "    gtZone=np.where(maskGT==1.0, maskGT,10000)\n",
    "    invPredZone=np.where(maskPred!=1.0, maskPred,10000)\n",
    "    \n",
    "    vp=np.where(gtZone==maskPred,1,0)\n",
    "    fn=np.where(maskPred-maskGT==-1,1,0)\n",
    "    fp=np.where(maskPred-maskGT==1,1,0)\n",
    "    vn=np.where(invPredZone==maskGT,1,0)\n",
    "    \n",
    "    print(np.sum(vp), np.sum(maskPred), np.sum(maskGT))\n",
    "    return (2*np.sum(vp))/(np.sum(maskPred)+np.sum(maskGT)), (np.sum(vn)/(np.sum(vn)+np.sum(fp))), (np.sum(vp)/(np.sum(vp)+np.sum(fn)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9c84b2-304e-4d03-9415-4abb143408fa",
   "metadata": {},
   "source": [
    "def transformation():\n",
    "    dtype= torch.float32\n",
    "    voxel_space =(1.5, 1.5, 2.0)\n",
    "    a_min=-200.0\n",
    "    a_max=300\n",
    "    b_min=0.0\n",
    "    b_max=1.0\n",
    "    clip=True\n",
    "    crop_bed_max_number_of_rows_to_remove=0\n",
    "    crop_bed_max_number_of_cols_to_remove=0\n",
    "    crop_bed_min_spatial_size=(300, -1, -1)\n",
    "    enable_fgbg2indices_feature=False\n",
    "    pos=1.0\n",
    "    neg=1.0\n",
    "    num_samples=1\n",
    "    roi_size=(96, 96, 96)\n",
    "    random_flip_prob=0.2\n",
    "    random_90_deg_rotation_prob=0.2\n",
    "    random_intensity_scale_prob=0.1\n",
    "    random_intensity_shift_prob=0.1\n",
    "    val_resize=(-1, -1, 250)\n",
    "\n",
    "    spacing = transforms.Identity()\n",
    "    if all([space > 0.0 for space in voxel_space]):\n",
    "        spacing = transforms.Spacingd(\n",
    "            keys=[\"image\", \"label\"], pixdim=voxel_space, mode=(\"bilinear\", \"nearest\")\n",
    "        ) # to change the dimension of the voxel to have less data to compute\n",
    "\n",
    "        posneg_label_croper_kwargs = {\n",
    "                \"keys\": [\"image\", \"label\"],\n",
    "                \"label_key\": \"label\",\n",
    "                \"spatial_size\": roi_size,\n",
    "                \"pos\": pos,\n",
    "                \"neg\": neg,\n",
    "                \"num_samples\": num_samples,\n",
    "                \"image_key\": \"image\",\n",
    "                \"allow_smaller\": True,\n",
    "        }\n",
    "\n",
    "        fgbg2indices = transforms.Identity()\n",
    "        if enable_fgbg2indices_feature:\n",
    "            fgbg2indices = transforms.FgBgToIndicesd(\n",
    "                    keys=[\"image\", \"label\"], image_key=\"label\", image_threshold=0.0\n",
    "            ) # to crop samples close to the label mask\n",
    "            posneg_label_croper_kwargs[\"fg_indices_key\"] = \"image_fg_indices\"\n",
    "            posneg_label_croper_kwargs[\"bg_indices_key\"] = \"image_bg_indices\"\n",
    "        else:\n",
    "            posneg_label_croper_kwargs[\"image_threshold\"] = 0.0\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Orientationd(keys=[\"image\", \"label\"], axcodes=\"LAS\", allow_missing_keys=True), # to have the same orientation\n",
    "                    spacing,\n",
    "                    transforms.ScaleIntensityRanged(\n",
    "                        keys=[\"image\"], a_min=a_min, a_max=a_max, b_min=b_min, b_max=b_max, clip=clip, allow_missing_keys=True\n",
    "                    ), # scales image from a values to b values\n",
    "                    CropBedd(\n",
    "                        keys=[\"image\", \"label\"], image_key=\"image\",\n",
    "                        max_number_of_rows_to_remove=crop_bed_max_number_of_rows_to_remove,\n",
    "                        max_number_of_cols_to_remove=crop_bed_max_number_of_cols_to_remove,\n",
    "                        min_spatial_size=crop_bed_min_spatial_size,\n",
    "                        axcodes_orientation=\"LAS\",\n",
    "                    ), # crop the bed from the image (useless data)\n",
    "                    transforms.CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\", allow_missing_keys=True), # remove useless background image part\n",
    "                    fgbg2indices,\n",
    "                    transforms.RandFlipd(keys=[\"image\", \"label\"], prob=random_flip_prob, spatial_axis=0, allow_missing_keys=True), # random flip on the X axis\n",
    "                    transforms.RandFlipd(keys=[\"image\", \"label\"], prob=random_flip_prob, spatial_axis=1, allow_missing_keys=True), # random flip on the Y axis\n",
    "                    transforms.RandFlipd(keys=[\"image\", \"label\"], prob=random_flip_prob, spatial_axis=2, allow_missing_keys=True), # random flip on the Z axis\n",
    "                    transforms.RandRotate90d(keys=[\"image\", \"label\"], prob=random_90_deg_rotation_prob, max_k=3, allow_missing_keys=True), # random 90 degree rotation\n",
    "                    transforms.RandScaleIntensityd(keys=\"image\", factors=0.1, prob=random_intensity_scale_prob), # random intensity scale\n",
    "                    transforms.RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=random_intensity_shift_prob), # random intensity shifting\n",
    "                    transforms.ToTensord(keys=[\"image\", \"label\"], dtype=dtype), # to have a PyTorch tensor as output\n",
    "                ]\n",
    "            )\n",
    "    return transform\n",
    "\n",
    "def loadModel(pathModelFile):\n",
    "    #map_location = torch.device('cpu') a faire pas ici mais dans unetr/model_module.py ligne 133 ou try faire ailleurs\n",
    "    model= SegmentationTask.load_from_checkpoint(pathModelFile)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def loadDicomImage(slices_folder):\n",
    "    image=torch.tensor([LoadImage(image_only=True)(slices_folder)])\n",
    "    image=((image/np.max(np.array(image)))*255)\n",
    "    return image\n",
    "\n",
    "\n",
    "def applyTransforms(transform, image):\n",
    "    print(\"----------------\")\n",
    "    print(image.ndim)\n",
    "    print(\"----------------\")\n",
    "    print(\"applyT\", image.shape)\n",
    "    image={\"image\":image, \"label\":torch.zeros_like(image),\"patient_id\":'201905984', \"has_meta\":True}\n",
    "    image=transform(image)\n",
    "    print(\"applyT\", image['image'].shape)\n",
    "    return image\n",
    "\n",
    "def applyTransforms2(transform, image):\n",
    "    # Assurez-vous que l'image est un tensor PyTorch\n",
    "    image = torch.tensor(image, dtype=torch.float32)\n",
    "    \n",
    "    image = (image / torch.max(image)) * 255\n",
    "    if image.ndim == 3:\n",
    "        image = image.unsqueeze(0)\n",
    "    print(\"----------------\")\n",
    "    print(image.ndim)\n",
    "    print(\"----------------\")\n",
    "    data = {\"image\": image, \"label\": torch.zeros_like(image), \"patient_id\": '201905984', \"has_meta\": True}\n",
    "    transformed = transform(data)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "def applyUNETR(dicoImage, model):\n",
    "    label =sliding_window_inference(inputs=dicoImage[\"image\"][None], \n",
    "                                            roi_size=(96, 96, 96), \n",
    "                                            sw_batch_size=4,\n",
    "                                            predictor=model,\n",
    "                                            overlap=0.5)\n",
    "\n",
    "    label = torch.argmax(label, dim=1, keepdim=True)\n",
    "    \n",
    "    size=label.shape\n",
    "    print(\"applyUNETR\", size[1], size[2], size[3], size[4])\n",
    "    dicoImage[\"label\"]=label.reshape((size[1], size[2], size[3], size[4]))\n",
    "    return dicoImage\n",
    "\n",
    "def disapplyTransforms(transform, dicoImage):\n",
    "    dicoImage = transform.inverse(dicoImage)\n",
    "    return dicoImage[\"label\"], dicoImage[\"image\"]\n",
    "\n",
    "\n",
    "\n",
    "def getLabelOfIRM_from_path(pathSlicesIRM, pathModelFile):\n",
    "    image = loadDicomImage(pathSlicesIRM)\n",
    "    transform = transformation()\n",
    "    dicoImage = applyTransforms(transform, image)\n",
    "    model = loadModel(pathModelFile)\n",
    "    dicoImage = applyUNETR(dicoImage, model)\n",
    "    label, imageT = disapplyTransforms(transform, dicoImage)\n",
    "    return image/255, label, imageT\n",
    "\n",
    "# Pipeline complet pour charger, transformer, segmenter et désappliquer les transformations\n",
    "def getLabelOfIRM_from_nifti(nifti_image: nib.Nifti1Image, pathModelFile: str):\n",
    "    transform = transformation()\n",
    "    transformed_image = applyTransforms2( transform, nifti_image.get_fdata())\n",
    "\n",
    "    model = loadModel(pathModelFile)\n",
    "    #dico_image = {\"image\": transformed_image, \"label\": torch.zeros_like(transformed_image)}\n",
    "    dico_image = applyUNETR(transformed_image, model)\n",
    "\n",
    "    label, imageT = disapplyTransforms(transform, dico_image)\n",
    "    return nifti_image.get_fdata() / 255, label, imageT\n",
    "\n",
    "def getLabelOfIRM_from_image(image, mask, pathModelFile):\n",
    "    image=torch.tensor([image])\n",
    "    image=((image/np.max(np.array(image)))*255)\n",
    "    transform = transformation()\n",
    "    dicoImage = applyTransforms(transform, image)\n",
    "    model = loadModel(pathModelFile)\n",
    "    dicoImage = applyUNETR(dicoImage, model)\n",
    "    label, imageT = disapplyTransforms(transform, dicoImage)\n",
    "    return image/255, label, imageT\n",
    "\n",
    "#pathSlicesIRM='/home/aurelien/Documents/Segmentation Métastases cérébrales et méningiomes par IA/UNETR/metastase_IA/BaseDonnée220Patients/201905984/RM'\n",
    "#pathModelFile=\"/home/aurelien/Documents/Segmentation Métastases cérébrales et méningiomes par IA/UNETR/metastase_IA/RunAll4/checkpoints/checkpoint-epoch=1599-val_loss=0.225.ckpt\"\n",
    "\n",
    "#image, label, imageT = getLabelOfIRM(pathSlicesIRM, pathModelFile)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d14e08ef-6071-443b-a0ec-b967307ebee5",
   "metadata": {},
   "source": [
    "def miseEnDossier(patient_id):\n",
    "    path_newDirRM = os.path.join(meta_data_dir, patient_id, \"RM/\")\n",
    "    path_newDirMETA = os.path.join(meta_data_dir, patient_id, \"META/\")\n",
    "    if not os.path.exists(path_newDirRM):\n",
    "        os.mkdir(path_newDirRM)\n",
    "    if not os.path.exists(path_newDirMETA):\n",
    "        os.mkdir(path_newDirMETA)\n",
    "    for mr in glob.glob(os.path.join(meta_data_dir, patient_id, \"MR*\")):\n",
    "        path_dir, name_file= os.path.split(mr)\n",
    "        os.rename(mr, str(path_newDirRM)+str(name_file))\n",
    "    for rs in glob.glob(os.path.join(meta_data_dir, patient_id, \"RS*\")):\n",
    "        path_dir, name_file= os.path.split(rs)\n",
    "        os.rename(rs, str(path_newDirMETA)+str(name_file))\n",
    "        \n",
    "def fusionMask(mask):\n",
    "        if (type(mask)==list):\n",
    "            premMask = mask[0]\n",
    "            for autMask in mask[1:]:\n",
    "                premMask = np.where(autMask > 0, autMask, premMask)\n",
    "            return premMask\n",
    "        else:\n",
    "            return mask\n",
    "    \n",
    "listeName=[]\n",
    "def load_dicom_with_mask(slices_folder, mask_file):\n",
    "    rt_struct = rt_utils.RTStructBuilder.create_from(slices_folder, mask_file)\n",
    "    maskAllAlone=[]\n",
    "    for i in rt_struct.get_roi_names():\n",
    "        if \"GTV\" in i or \"recid\" in i or \"FRONTAL\" in i or \"GTC\" in i or \"Cerebelleux\" in i or \"PARIET\" in i or \"gtv\" in i or \"M1.\" in i or \"M2.\" in i or \"FRONTAL\" in i:\n",
    "            if \"patient\" not in i and \"POST OP\" not in i and \"Préop\" not in i and \"External\" not in i and \"cav\" not in i and \"Cav\" not in i and \"cavite\" not in i and \"cavité\" not in i and \"Cavité\" not in i and \"PTV\" not in i and \"ANCIEN\" not in i and \"Ancien\" not in i and \"ANC\" not in i and \"Anecien\" not in i and \"PTC\" not in i:\n",
    "                maskAllAlone.append(rt_struct.get_roi_mask_by_name(i).astype(np.float32))\n",
    "                listeName.append(i)\n",
    "    mask = fusionMask(maskAllAlone)\n",
    "    img = np.array(LoadImage( image_only=True)(slices_folder))\n",
    "\n",
    "    img = np.rot90(img)\n",
    "    img = np.flip(img, 0)\n",
    "    img = (img/np.max(img))*255\n",
    "    return img, np.array(mask)\n",
    "\n",
    "\n",
    "def load_dicom_series_without_mask(patient_folder):\n",
    "    img = LoadImage( image_only=True)(patient_folder)\n",
    "    mask = np.zeros_like(img)\n",
    "    return np.array(img), mask\n",
    "  \n",
    "def filter_patients_with_meta(patient_id: str) -> bool:\n",
    "    miseEnDossier(patient_id)\n",
    "    # if no folder in patient directory\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"*\"))) == 0:\n",
    "        return False\n",
    "\n",
    "    # if no named folders \"META\" or \"RM\"\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"META\"))) == 0 or len(glob.glob(os.path.join(meta_data_dir, patient_id, \"RM\"))) == 0:\n",
    "        return False\n",
    "    \n",
    "    # if no dicom image in the META folder\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"META\", \"*\"))) == 0:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def filter_patients_without_meta(patient_id: str) -> bool:\n",
    "    miseEnDossier(patient_id)\n",
    "    # if no folder in patient directory\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"*\"))) == 0:\n",
    "        return False\n",
    "\n",
    "    # if no named folders \"META\" or \"RM\"\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"RM\"))) == 0:\n",
    "        return False\n",
    "\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"META\"))) != 0:\n",
    "        if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"META\", \"*\"))) != 0:\n",
    "            return False\n",
    "    return True"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4441d99c",
   "metadata": {},
   "source": [
    "from typing import List\n",
    "import pydicom\n",
    "from io import BytesIO\n",
    "import os \n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from monai.transforms import Compose, Orientationd, ScaleIntensityRanged, CropForegroundd, ToTensord\n",
    "from monai.transforms import RandFlipd, RandRotate90d, RandScaleIntensityd, RandShiftIntensityd\n",
    "import torch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from unetr.model_module import SegmentationTask\n",
    "\n",
    "# fonction de chargement de dicoms en mémoire pour le test de conversion en nifti\n",
    "def load_dicom_files_from_directory(directory_path):\n",
    "    dicom_datasets = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".dcm\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, 'rb') as file:\n",
    "                dicom_file = pydicom.dcmread(BytesIO(file.read()))\n",
    "                dicom_datasets.append(dicom_file)\n",
    "    return dicom_datasets\n",
    "\n",
    "\n",
    "# chargement de données médicales dicoms en mémoire depuis un répertoire de l'ordinateur : \n",
    "\n",
    "pathSlicesIRM = '/Users/romain/Documents/P_R_O_J_E_C_T_S/IRM-Project/mbiaDataDownloads/DATA_VERITE_TERRAIN/RM'\n",
    "\n",
    "# lecture des fichiers dicom avec pydicom\n",
    "\n",
    "dicom_datasets = load_dicom_files_from_directory(pathSlicesIRM)\n",
    "\n",
    "#################### API #############################################################################\n",
    "\n",
    "\n",
    "def dicom_to_nifti_in_memory(dicom_datasets: List[pydicom.Dataset]) -> nib.Nifti1Image:\n",
    "    image_slices = [ds.pixel_array for ds in dicom_datasets]\n",
    "    volume_3d = np.stack(image_slices, axis=-1)\n",
    "    affine = np.eye(4) # necessaire pour les algorithmes de traitement d'images médicales, ça permet de savoir comment les voxels sont disposés dans l'espace\n",
    "    nifti_image = nib.Nifti1Image(volume_3d, affine)\n",
    "    return nifti_image\n",
    "\n",
    "\n",
    "niftis =  dicom_to_nifti_in_memory(dicom_datasets)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2c3a447-3988-4e5c-9773-0733bed22d92",
   "metadata": {},
   "source": [
    "# Chemins vers les dossiers d'images DICOM et le modèle UNETR\n",
    "pathSlicesIRM = '/Users/romain/Documents/P_R_O_J_E_C_T_S/IRM-Project/mbiaDataDownloads/DATA_VERITE_TERRAIN/RM'\n",
    "pathSlicesIRM2 = '/Users/romain/Documents/P_R_O_J_E_C_T_S/IRM-Project/mbiaDataDownloads/nifti_s/201704321/image.nii.gz'\n",
    "pathModelFile = '/Users/romain/Downloads/Modeles_Pre_Entraines/checkpoint_epoch1599_val_loss0255.cpkt'\n",
    "\n",
    "# Charger les étiquettes pour les images DICOM\n",
    "#image, label, imageT = getLabelOfIRM_from_path(pathSlicesIRM2, pathModelFile)\n",
    "image, label, imageT = getLabelOfIRM_from_nifti(niftis, pathModelFile)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Label shape:\", label.shape)\n",
    "print(\"Transformed image shape:\", imageT.shape)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
